PYTHONPATH=. python benchmarks/scaling_adapters/deployment/launcher.py --user bsc98 --queue acc_debug --max-duration 00:30:00 --results-path benchmarks/scaling_adapters/definitive_results/gpu_capacity/experiments_joan/llama-2-7b/mean_dataset/rank_32 --default-server-args "{'--disable_log_stats': '', '--model_dir': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', '--tokenizer_mode': 'auto', '--max_total_token_num': '82528', '--swap': ''}" --default-benchmark-args "{'--backend': 'slora', '--disable-tqdm': '', '--dataset-path': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/dummy_dataset_mean.json', '--endpoint': '/generate_stream', '--model': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b', '--save-result': '', '--lora-dir': '/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-2-7b/lora/yard1_sql-lora-test_dummy_rank_32_simplified', '--infinite-behaviour': '', '--total-time': '1200'}" --test-server-args "{}" --test-benchmark-args "{'--lora-number': ['32', '64', '96', '128', '160', '192', '256', '320', '384', '448', '512', '640', '768'], '--request-rate-by-lora': ['0.4', '0.2', '0.1', '0.05', '0.025', '0.0125']}"
